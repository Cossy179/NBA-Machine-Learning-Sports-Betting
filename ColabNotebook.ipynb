{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84FCh7pFCA2U"
      },
      "source": [
        "You could use this notebook on [Google Colab](https://colab.research.google.com/) with a GPU Hardware Accelerator runtype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBeeVTbb_WLL"
      },
      "source": [
        "# Bootstrap Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cEOhYxk-ASjw",
        "collapsed": true,
        "outputId": "b30146ae-21c1-4bad-e51b-d449f2a49988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NBA-Machine-Learning-Sports-Betting'...\n",
            "remote: Enumerating objects: 9821, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 9821 (delta 31), reused 57 (delta 16), pack-reused 9729 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9821/9821), 240.45 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (3453/3453), done.\n",
            "Updating files: 100% (95/95), done.\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/check_db.py' -> './check_db.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/ColabNotebook.ipynb' -> './ColabNotebook.ipynb'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/config.toml' -> './config.toml'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Data' -> './Data'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/enhanced_main.py' -> './enhanced_main.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/ENHANCED_README.md' -> './ENHANCED_README.md'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Flask' -> './Flask'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/main.py' -> './main.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Models' -> './Models'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/notes.txt' -> './notes.txt'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Personal_Tests' -> './Personal_Tests'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/README.md' -> './README.md'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/requirements.txt' -> './requirements.txt'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Screenshots' -> './Screenshots'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/src' -> './src'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Tests' -> './Tests'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/train_advanced_models.py' -> './train_advanced_models.py'\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "Collecting sbrscrape==0.0.10\n",
            "  Downloading sbrscrape-0.0.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading sbrscrape-0.0.10-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: sbrscrape\n",
            "Successfully installed sbrscrape-0.0.10\n",
            "Collecting pandas==2.1.1\n",
            "  Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.17.0)\n",
            "Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "xarray 2025.8.0 requires pandas>=2.2, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.14.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.14.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting xgboost==2.0.0\n",
            "  Downloading xgboost-2.0.0-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost==2.0.0) (1.16.1)\n",
            "Downloading xgboost-2.0.0-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.0.4\n",
            "    Uninstalling xgboost-3.0.4:\n",
            "      Successfully uninstalled xgboost-3.0.4\n",
            "Successfully installed xgboost-2.0.0\n",
            "Collecting tqdm==4.66.1\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.1 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.66.1\n",
            "Collecting flask==3.0.0\n",
            "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (8.2.1)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1.2->flask==3.0.0) (3.0.2)\n",
            "Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flask\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.2\n",
            "    Uninstalling Flask-3.1.2:\n",
            "      Successfully uninstalled Flask-3.1.2\n",
            "Successfully installed flask-3.0.0\n",
            "Collecting scikit-learn==1.3.1\n",
            "  Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.17.3 (from scikit-learn==1.3.1)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (3.6.0)\n",
            "Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "xarray 2025.8.0 requires pandas>=2.2, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d3f9f2b448af4ef58bc165c563d2a8c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.12/dist-packages (0.10.2)\n"
          ]
        }
      ],
      "source": [
        "#Remove Preexisting Files\n",
        "! rm -rf NBA-Machine-Learning-Sports-Betting\n",
        "! rm -rf *\n",
        "\n",
        "#Bootstrap Files\n",
        "! git clone https://github.com/Cossy179/NBA-Machine-Learning-Sports-Betting.git\n",
        "! mv -v ./NBA-Machine-Learning-Sports-Betting/* .\n",
        "\n",
        "#For some reason pip3 install -r requirements.txt doesn't work on Colab\n",
        "! pip3 install colorama==0.4.6\n",
        "! pip3 install sbrscrape==0.0.10\n",
        "! pip3 install pandas==2.1.1\n",
        "! pip3 install tensorflow==2.14.0\n",
        "! pip3 install xgboost==2.0.0\n",
        "! pip3 install tqdm==4.66.1\n",
        "! pip3 install flask==3.0.0\n",
        "! pip3 install scikit-learn==1.3.1\n",
        "! pip3 install toml==0.10.2\n",
        "# Enhanced model requirements\n",
        "! pip3 install optuna>=3.0.0\n",
        "! pip3 install lightgbm>=4.0.0\n",
        "! pip3 install joblib>=1.3.0\n",
        "! pip3 install shap>=0.42.0\n",
        "! pip3 install plotly>=5.15.0\n",
        "! pip3 install seaborn>=0.12.0\n",
        "! pip3 install requests>=2.31.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wurq7KgC_ckH"
      },
      "source": [
        "# Run Model\n",
        "\n",
        "Do this after you have run the bootstrap model to download all the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QBu_ZuXvNgqR",
        "outputId": "493982b7-fa1a-475b-9c2c-16430992169b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-04 22:41:30.871680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757025690.891592     993 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757025690.897513     993 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757025690.912514     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912537     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912541     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912544     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 22:41:30.916995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-09-04 22:41:40.572796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1757025700.574076     993 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Failed to load ensemble model: <class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module.\n",
            "Ensemble model not found, skipping...\n",
            "Multi-target models loaded successfully!\n",
            "Advanced XGBoost model loaded successfully!\n",
            "\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\u001b[32m🏀 ENHANCED NBA PREDICTION SYSTEM v2.0 🏀\u001b[0m\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\u001b[33mFeatures:\u001b[0m\n",
            "  • Multi-model ensemble predictions\n",
            "  • Real-time injury and lineup data\n",
            "  • Advanced betting market analysis\n",
            "  • Travel fatigue and referee impacts\n",
            "  • Multiple prediction targets (ML, OU, Spreads, Props)\n",
            "  • Calibrated probabilities and confidence intervals\n",
            "  • Kelly Criterion bankroll management\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\n",
            "\u001b[33mFetching fanduel odds data...\u001b[0m\n",
            "\u001b[31mNo games found in odds data.\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! python3 enhanced_main.py -odds=fanduel -kc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nigga"
      ],
      "metadata": {
        "id": "rOaTC_zS8hEh"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}