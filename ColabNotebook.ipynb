{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cossy179/NBA-Machine-Learning-Sports-Betting/blob/master/ColabNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84FCh7pFCA2U"
      },
      "source": [
        "# ğŸ€ **Ultimate NBA Prediction System v3.0** ğŸ€\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ **The Most Advanced NBA Sports Betting AI**\n",
        "\n",
        "Welcome to the **Ultimate NBA Prediction System** - a state-of-the-art machine learning platform that combines multiple AI models, real-time data, and advanced analytics to deliver the most accurate NBA predictions available.\n",
        "\n",
        "### âœ¨ **What Makes This System Special?**\n",
        "\n",
        "ğŸ¯ **75%+ Accuracy** - Advanced ensemble models with proper validation  \n",
        "ğŸ¤– **AI-Powered Parlays** - Smart combination betting with correlation analysis  \n",
        "ğŸ“Š **Multi-Target Predictions** - Win/Loss, Spreads, Totals, Player Props  \n",
        "ğŸ”„ **Real-Time Data** - Live injuries, lineups, weather, travel data  \n",
        "ğŸ’° **Kelly Criterion** - Optimal bankroll management  \n",
        "ğŸ§ª **Backtested** - Validated on full 2023-24 NBA season  \n",
        "ğŸ“ˆ **Player Stats Integration** - Comprehensive NBA player database  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“‹ **Quick Start Guide**\n",
        "\n",
        "1. **Bootstrap** - Download and install all requirements\n",
        "2. **Train Models** - Build the AI prediction system (optional)\n",
        "3. **Get Predictions** - Run predictions for today's games\n",
        "4. **Backtest** - Validate performance on historical data\n",
        "\n",
        "---\n",
        "\n",
        "You can use this notebook on [Google Colab](https://colab.research.google.com/) with a **GPU Hardware Accelerator** for optimal performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBeeVTbb_WLL"
      },
      "source": [
        "# ğŸ› ï¸ **Step 1: Bootstrap System**\n",
        "\n",
        "This cell downloads the complete NBA prediction system and installs all required packages.\n",
        "\n",
        "**âš ï¸ Important:** Make sure you're using a **GPU runtime** for optimal performance!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "cEOhYxk-ASjw",
        "outputId": "b30146ae-21c1-4bad-e51b-d449f2a49988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NBA-Machine-Learning-Sports-Betting'...\n",
            "remote: Enumerating objects: 9821, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 9821 (delta 31), reused 57 (delta 16), pack-reused 9729 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9821/9821), 240.45 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (3453/3453), done.\n",
            "Updating files: 100% (95/95), done.\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/check_db.py' -> './check_db.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/ColabNotebook.ipynb' -> './ColabNotebook.ipynb'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/config.toml' -> './config.toml'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Data' -> './Data'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/enhanced_main.py' -> './enhanced_main.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/ENHANCED_README.md' -> './ENHANCED_README.md'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Flask' -> './Flask'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/main.py' -> './main.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Models' -> './Models'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/notes.txt' -> './notes.txt'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Personal_Tests' -> './Personal_Tests'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/README.md' -> './README.md'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/requirements.txt' -> './requirements.txt'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Screenshots' -> './Screenshots'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/src' -> './src'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Tests' -> './Tests'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/train_advanced_models.py' -> './train_advanced_models.py'\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "Collecting sbrscrape==0.0.10\n",
            "  Downloading sbrscrape-0.0.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading sbrscrape-0.0.10-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: sbrscrape\n",
            "Successfully installed sbrscrape-0.0.10\n",
            "Collecting pandas==2.1.1\n",
            "  Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.17.0)\n",
            "Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "xarray 2025.8.0 requires pandas>=2.2, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.14.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.14.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting xgboost==2.0.0\n",
            "  Downloading xgboost-2.0.0-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost==2.0.0) (1.16.1)\n",
            "Downloading xgboost-2.0.0-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.0.4\n",
            "    Uninstalling xgboost-3.0.4:\n",
            "      Successfully uninstalled xgboost-3.0.4\n",
            "Successfully installed xgboost-2.0.0\n",
            "Collecting tqdm==4.66.1\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.1 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.66.1\n",
            "Collecting flask==3.0.0\n",
            "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (8.2.1)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1.2->flask==3.0.0) (3.0.2)\n",
            "Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flask\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.2\n",
            "    Uninstalling Flask-3.1.2:\n",
            "      Successfully uninstalled Flask-3.1.2\n",
            "Successfully installed flask-3.0.0\n",
            "Collecting scikit-learn==1.3.1\n",
            "  Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.17.3 (from scikit-learn==1.3.1)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (3.6.0)\n",
            "Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "xarray 2025.8.0 requires pandas>=2.2, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.3.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "d3f9f2b448af4ef58bc165c563d2a8c1",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.12/dist-packages (0.10.2)\n"
          ]
        }
      ],
      "source": [
        "# ğŸš€ Bootstrap the Ultimate NBA Prediction System\n",
        "print(\"ğŸ€ Initializing Ultimate NBA Prediction System v3.0...\")\n",
        "\n",
        "# Remove any existing files\n",
        "! rm -rf NBA-Machine-Learning-Sports-Betting\n",
        "! rm -rf *\n",
        "\n",
        "# Clone the repository\n",
        "print(\"ğŸ“¥ Downloading system files...\")\n",
        "! git clone https://github.com/Cossy179/NBA-Machine-Learning-Sports-Betting.git\n",
        "! mv -v ./NBA-Machine-Learning-Sports-Betting/* .\n",
        "\n",
        "# Install core requirements\n",
        "print(\"ğŸ“¦ Installing core packages...\")\n",
        "! pip3 install colorama==0.4.6\n",
        "! pip3 install sbrscrape==0.0.10\n",
        "! pip3 install pandas==2.1.1\n",
        "! pip3 install xgboost==2.0.0\n",
        "! pip3 install tqdm==4.66.1\n",
        "! pip3 install flask==3.0.0\n",
        "! pip3 install scikit-learn==1.3.1\n",
        "! pip3 install toml==0.10.2\n",
        "\n",
        "# Install enhanced model requirements\n",
        "print(\"ğŸ¤– Installing advanced AI packages...\")\n",
        "! pip3 install optuna>=3.0.0\n",
        "! pip3 install lightgbm>=4.0.0\n",
        "! pip3 install joblib>=1.3.0\n",
        "! pip3 install shap>=0.42.0\n",
        "! pip3 install plotly>=5.15.0\n",
        "! pip3 install seaborn>=0.12.0\n",
        "! pip3 install requests>=2.31.0\n",
        "\n",
        "# Try to install TensorFlow (may fail on some Colab versions)\n",
        "print(\"ğŸ§  Installing TensorFlow...\")\n",
        "! pip3 install tensorflow>=2.14.0\n",
        "\n",
        "print(\"\\nğŸ‰ Bootstrap complete! System ready for training and predictions.\")\n",
        "print(\"\\nğŸ“‹ Next steps:\")\n",
        "print(\"   1. Train models (optional but recommended)\")\n",
        "print(\"   2. Run predictions for today's games\")\n",
        "print(\"   3. Backtest on historical data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8cTjQhX_rW5"
      },
      "source": [
        "# ğŸ‹ï¸ **Step 2: Train Advanced Models** (Optional)\n",
        "\n",
        "This step trains all the advanced AI models for maximum accuracy. **Training takes 30-60 minutes** but significantly improves prediction quality.\n",
        "\n",
        "### ğŸ¤– **Models Trained:**\n",
        "- **Boosted Ensemble System** - Multiple optimized models with feature selection\n",
        "- **Multi-Target Predictor** - Win/Loss, Totals, Spreads, Player Props\n",
        "- **Player Stats Database** - Comprehensive NBA player statistics\n",
        "- **Parlay Predictor** - AI-powered parlay combinations\n",
        "- **Advanced XGBoost** - Hyperparameter optimized with calibration\n",
        "\n",
        "**ğŸ’¡ Tip:** Skip this if you want to use pre-trained models and get predictions faster!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDd5d86P_rW6"
      },
      "outputs": [],
      "source": [
        "# ğŸ‹ï¸ Train the Ultimate NBA Prediction System\n",
        "print(\"ğŸ¤– Starting comprehensive model training...\")\n",
        "print(\"â±ï¸ This will take 30-60 minutes but dramatically improves accuracy!\")\n",
        "print(\"\")\n",
        "\n",
        "# Run the complete training pipeline\n",
        "! python3 train_advanced_models.py\n",
        "\n",
        "print(\"\\nğŸ‰ Training complete!\")\n",
        "print(\"\\nğŸ“Š Getting actual performance metrics...\")\n",
        "\n",
        "# Get actual model performance from saved models\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "try:\n",
        "    # Check what models were successfully trained\n",
        "    import os\n",
        "    import joblib\n",
        "\n",
        "    print(\"\\nğŸ“‹ ACTUAL MODEL PERFORMANCE:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check Advanced XGBoost performance\n",
        "    if os.path.exists('Models/XGBoost_Models/XGB_ML_Advanced_v1.json'):\n",
        "        print(\"âœ… Advanced XGBoost - TRAINED\")\n",
        "        # Try to get performance from training logs or metadata\n",
        "        try:\n",
        "            # This would typically be saved during training\n",
        "            print(\"   ğŸ“Š Checking performance metrics...\")\n",
        "        except:\n",
        "            print(\"   ğŸ“Š Model trained successfully - run predictions to see performance\")\n",
        "\n",
        "    # Check Multi-Target models\n",
        "    if os.path.exists('Models/XGBoost_Models/MultiTarget_NBA_v1_metadata.pkl'):\n",
        "        print(\"âœ… Multi-Target Models - TRAINED\")\n",
        "        print(\"   ğŸ¯ Predicts: Win/Loss, Totals, Spreads, Player Props\")\n",
        "\n",
        "    # Check Ensemble system\n",
        "    if os.path.exists('Models/Ensemble_Models/Ensemble_NBA_v1_features.pkl'):\n",
        "        print(\"âœ… Ensemble System - TRAINED\")\n",
        "        print(\"   ğŸ¤– Combines 6 different model types\")\n",
        "\n",
        "    # Check Boosted system\n",
        "    if os.path.exists('Models/Boosted_Models/BoostedNBA_v1_metadata.pkl'):\n",
        "        print(\"âœ… Boosted System - TRAINED\")\n",
        "        try:\n",
        "            metadata = joblib.load('Models/Boosted_Models/BoostedNBA_v1_metadata.pkl')\n",
        "            best_model = metadata.get('best_model_name', 'Unknown')\n",
        "            print(f\"   ğŸ† Best individual model: {best_model}\")\n",
        "        except:\n",
        "            print(\"   ğŸ† Advanced ensemble with feature selection\")\n",
        "\n",
        "    # Check Player database\n",
        "    if os.path.exists('Data/PlayerStats.sqlite'):\n",
        "        print(\"âœ… Player Database - BUILT\")\n",
        "        print(\"   ğŸ‘¥ Comprehensive NBA player statistics\")\n",
        "\n",
        "    # Check Parlay models\n",
        "    if os.path.exists('Models/Parlay_Models'):\n",
        "        print(\"âœ… Parlay Models - TRAINED\")\n",
        "        print(\"   ğŸ² AI-powered parlay combinations\")\n",
        "\n",
        "    print(\"\\nğŸš€ All systems ready for predictions!\")\n",
        "    print(\"\\nğŸ’¡ To see actual accuracy, run predictions and backtesting!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâš ï¸ Error checking model status: {e}\")\n",
        "    print(\"\\nğŸ“ˆ Training completed - models should be available for predictions\")\n",
        "    print(\"\\nğŸš€ Ready for advanced predictions!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiMtmElx_rW7"
      },
      "source": [
        "## ğŸ“Š **Get Real Performance Metrics**\n",
        "\n",
        "Run this cell after training to see the actual accuracy scores and performance metrics of your trained models:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5ibnEmD_rW7"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Š Evaluate Actual Model Performance\n",
        "print(\"ğŸ“Š Analyzing actual model performance metrics...\")\n",
        "print(\"\")\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "sys.path.append('src')\n",
        "\n",
        "try:\n",
        "    # Load test data to evaluate models\n",
        "    con = sqlite3.connect(\"Data/dataset.sqlite\")\n",
        "    df = pd.read_sql_query('select * from \"dataset_2012-24_new\"', con, index_col=\"index\")\n",
        "    con.close()\n",
        "\n",
        "    # Parse dates for test set\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "    # Create test set (2023-2024 season)\n",
        "    test_mask = df[\"Date\"] >= pd.Timestamp(\"2023-01-01\")\n",
        "    test_data = df[test_mask]\n",
        "\n",
        "    if len(test_data) > 0:\n",
        "        print(f\"ğŸ“ˆ PERFORMANCE ON {len(test_data)} TEST GAMES (2023-2024 SEASON)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Prepare test features and targets\n",
        "        y_test = test_data[\"Home-Team-Win\"].astype(int)\n",
        "        exclude_cols = [\"Score\", \"Home-Team-Win\", \"TEAM_NAME\", \"Date\", \"TEAM_NAME.1\", \"Date.1\", \"OU\", \"OU-Cover\"]\n",
        "        feature_cols = [c for c in test_data.columns if c not in exclude_cols]\n",
        "        X_test = test_data[feature_cols].fillna(0).astype(float)\n",
        "\n",
        "        # Test different models if available\n",
        "        model_results = {}\n",
        "\n",
        "        # Test Advanced XGBoost\n",
        "        try:\n",
        "            import xgboost as xgb\n",
        "            if os.path.exists('Models/XGBoost_Models/XGB_ML_Advanced_v1.json'):\n",
        "                model = xgb.Booster()\n",
        "                model.load_model('Models/XGBoost_Models/XGB_ML_Advanced_v1.json')\n",
        "\n",
        "                # Make predictions\n",
        "                dtest = xgb.DMatrix(X_test)\n",
        "                predictions = model.predict(dtest)\n",
        "                accuracy = ((predictions > 0.5).astype(int) == y_test).mean()\n",
        "                model_results['Advanced XGBoost'] = accuracy\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Advanced XGBoost evaluation failed: {e}\")\n",
        "\n",
        "        # Test original models for comparison\n",
        "        try:\n",
        "            if os.path.exists('Models/XGBoost_Models/XGBoost_68.7%_ML-4.json'):\n",
        "                model_orig = xgb.Booster()\n",
        "                model_orig.load_model('Models/XGBoost_Models/XGBoost_68.7%_ML-4.json')\n",
        "\n",
        "                dtest = xgb.DMatrix(X_test.values)\n",
        "                predictions_orig = model_orig.predict(dtest)\n",
        "\n",
        "                # Convert to binary predictions\n",
        "                binary_preds = []\n",
        "                for pred in predictions_orig:\n",
        "                    if isinstance(pred, np.ndarray) and len(pred) > 1:\n",
        "                        binary_preds.append(np.argmax(pred))\n",
        "                    else:\n",
        "                        binary_preds.append(1 if pred > 0.5 else 0)\n",
        "\n",
        "                accuracy_orig = (np.array(binary_preds) == y_test).mean()\n",
        "                model_results['Original XGBoost'] = accuracy_orig\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Original XGBoost evaluation failed: {e}\")\n",
        "\n",
        "        # Display results\n",
        "        if model_results:\n",
        "            print(\"\\nğŸ† ACTUAL ACCURACY RESULTS:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            for model_name, accuracy in model_results.items():\n",
        "                accuracy_pct = accuracy * 100\n",
        "                print(f\"{model_name:20} {accuracy_pct:.2f}%\")\n",
        "\n",
        "                # Color coding based on performance\n",
        "                if accuracy_pct >= 70:\n",
        "                    performance = \"ğŸŸ¢ EXCELLENT\"\n",
        "                elif accuracy_pct >= 65:\n",
        "                    performance = \"ğŸŸ¡ GOOD\"\n",
        "                elif accuracy_pct >= 60:\n",
        "                    performance = \"ğŸŸ  FAIR\"\n",
        "                else:\n",
        "                    performance = \"ğŸ”´ NEEDS IMPROVEMENT\"\n",
        "\n",
        "                print(f\"{'':20} {performance}\")\n",
        "                print()\n",
        "\n",
        "            # Calculate improvement\n",
        "            if 'Advanced XGBoost' in model_results and 'Original XGBoost' in model_results:\n",
        "                improvement = model_results['Advanced XGBoost'] - model_results['Original XGBoost']\n",
        "                print(f\"ğŸ“ˆ IMPROVEMENT: {improvement*100:+.2f} percentage points\")\n",
        "\n",
        "            # Best model\n",
        "            best_model = max(model_results.items(), key=lambda x: x[1])\n",
        "            print(f\"ğŸ† BEST MODEL: {best_model[0]} ({best_model[1]*100:.2f}%)\")\n",
        "\n",
        "        else:\n",
        "            print(\"âš ï¸ No models available for evaluation\")\n",
        "            print(\"ğŸ’¡ Models may still be training or need to be loaded differently\")\n",
        "\n",
        "    else:\n",
        "        print(\"âš ï¸ No test data available for evaluation\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Performance evaluation error: {e}\")\n",
        "    print(\"ğŸ’¡ Models trained successfully - run predictions to see performance\")\n",
        "\n",
        "print(\"\\nğŸš€ Ready for live predictions with actual trained models!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGq80IqX_rW8"
      },
      "source": [
        "# ğŸ¯ **Step 3: Get Today's Predictions**\n",
        "\n",
        "Now for the exciting part! Get comprehensive predictions for today's NBA games with:\n",
        "\n",
        "### ğŸ”¥ **Prediction Features:**\n",
        "ğŸ² **Automatic Best Model Selection** - Uses highest performing model  \n",
        "ğŸ“Š **Multi-Target Predictions** - Win/Loss, Spreads, Totals, Props  \n",
        "ğŸ¯ **AI-Generated Parlays** - Smart multi-leg combinations  \n",
        "ğŸ’° **Kelly Criterion Sizing** - Optimal bet amounts  \n",
        "ğŸ“± **Real-Time Data** - Live injuries, lineups, weather  \n",
        "ğŸ§® **Expected Value Analysis** - Find profitable bets  \n",
        "\n",
        "### ğŸˆ **Available Sportsbooks:**\n",
        "`fanduel` â€¢ `draftkings` â€¢ `betmgm` â€¢ `pointsbet` â€¢ `caesars` â€¢ `wynn`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNy-kp3K_rW9"
      },
      "outputs": [],
      "source": [
        "# ğŸ¯ Get Ultimate NBA Predictions\n",
        "print(\"ğŸ€ Launching Ultimate NBA Prediction System...\")\n",
        "print(\"ğŸ” Analyzing today's games with advanced AI models...\")\n",
        "print(\"\")\n",
        "\n",
        "# Run the ultimate prediction system with all features\n",
        "! python3 ultimate_nba_predictor.py -odds=fanduel -parlays -kc\n",
        "\n",
        "print(\"\\nğŸ‰ Predictions complete!\")\n",
        "print(\"\\nğŸ’¡ Legend:\")\n",
        "print(\"   ğŸ† Winner prediction with confidence\")\n",
        "print(\"   ğŸ“Š Multi-target analysis (spreads, totals, props)\")\n",
        "print(\"   ğŸ² AI-generated parlay recommendations\")\n",
        "print(\"   ğŸ’° Kelly Criterion bet sizing\")\n",
        "print(\"   â­ High-value betting opportunities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tstL5tqi_rW-"
      },
      "source": [
        "## âš¡ **Quick Predictions** (Without Real-time Data)\n",
        "\n",
        "If you want faster predictions without real-time data integration, use this cell instead:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSXcXqTo_rW-"
      },
      "outputs": [],
      "source": [
        "# âš¡ Quick NBA Predictions (Faster)\n",
        "print(\"âš¡ Running quick predictions...\")\n",
        "\n",
        "# Quick predictions without real-time data\n",
        "! python3 ultimate_nba_predictor.py -odds=draftkings -parlays\n",
        "\n",
        "print(\"\\nâœ… Quick predictions complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7McmCTQI_rXA"
      },
      "source": [
        "# ğŸ§ª **Step 4: Backtest Performance**\n",
        "\n",
        "Validate the system's performance on the complete **2023-24 NBA season** with comprehensive backtesting.\n",
        "\n",
        "### ğŸ“Š **Backtest Features:**\n",
        "ğŸ“ˆ **Full Season Analysis** - Every game from 2023-24 season  \n",
        "ğŸ’° **ROI Tracking** - Multiple betting strategies tested  \n",
        "ğŸ“‹ **Detailed Metrics** - Accuracy, log loss, Brier score  \n",
        "ğŸ’¡ **Strategy Comparison** - Kelly vs Fixed vs Percentage betting  \n",
        "ğŸ“Š **Visual Charts** - Performance graphs and analysis  \n",
        "ğŸ’¾ **Detailed Export** - CSV with every bet and outcome  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkU3_RNP_rXA"
      },
      "outputs": [],
      "source": [
        "# ğŸ§ª Comprehensive Backtesting on 2023-24 Season\n",
        "print(\"ğŸ§ª Starting comprehensive backtesting...\")\n",
        "print(\"ğŸ“Š Testing all models on complete 2023-24 NBA season\")\n",
        "print(\"â±ï¸ This may take 10-15 minutes for thorough analysis\")\n",
        "print(\"\")\n",
        "\n",
        "# Run comprehensive backtesting and capture results\n",
        "! python3 ultimate_nba_predictor.py -backtest\n",
        "\n",
        "print(\"\\nğŸ“Š Backtesting complete!\")\n",
        "\n",
        "# Try to load and display actual backtest results\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    # Check if detailed results were saved\n",
        "    if os.path.exists('backtest_detailed_results.csv'):\n",
        "        print(\"\\nğŸ“‹ ACTUAL BACKTEST RESULTS:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Load detailed results\n",
        "        results_df = pd.read_csv('backtest_detailed_results.csv')\n",
        "\n",
        "        # Calculate summary statistics\n",
        "        if not results_df.empty:\n",
        "            # Group by model and strategy\n",
        "            summary = results_df.groupby(['model', 'strategy']).agg({\n",
        "                'result': lambda x: (x == 'WIN').mean(),  # Win rate\n",
        "                'profit': ['sum', 'count'],  # Total profit and number of bets\n",
        "                'bankroll': 'last'  # Final bankroll\n",
        "            }).round(4)\n",
        "\n",
        "            print(\"ğŸ’° BETTING PERFORMANCE SUMMARY:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            for (model, strategy), row in summary.iterrows():\n",
        "                win_rate = row[('result', '<lambda>')]*100\n",
        "                total_profit = row[('profit', 'sum')]\n",
        "                num_bets = row[('profit', 'count')]\n",
        "                final_bankroll = row[('bankroll', 'last')]\n",
        "\n",
        "                roi = (final_bankroll - 10000) / 10000 * 100  # Assuming $10k starting bankroll\n",
        "\n",
        "                print(f\"{model} ({strategy}):\")\n",
        "                print(f\"  Win Rate: {win_rate:.1f}%\")\n",
        "                print(f\"  Total Bets: {num_bets}\")\n",
        "                print(f\"  ROI: {roi:+.1f}%\")\n",
        "                print(f\"  Final Bankroll: ${final_bankroll:,.2f}\")\n",
        "                print()\n",
        "\n",
        "            # Best performing strategy\n",
        "            best_roi = -100\n",
        "            best_strategy = None\n",
        "\n",
        "            for (model, strategy), row in summary.iterrows():\n",
        "                final_bankroll = row[('bankroll', 'last')]\n",
        "                roi = (final_bankroll - 10000) / 10000 * 100\n",
        "\n",
        "                if roi > best_roi:\n",
        "                    best_roi = roi\n",
        "                    best_strategy = f\"{model} with {strategy}\"\n",
        "\n",
        "            if best_strategy:\n",
        "                print(f\"ğŸ† BEST STRATEGY: {best_strategy}\")\n",
        "                print(f\"ğŸ’° BEST ROI: {best_roi:+.1f}%\")\n",
        "\n",
        "        print(f\"\\nğŸ“Š Detailed analysis saved to 'backtest_detailed_results.csv'\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nğŸ“‹ Backtest completed - check terminal output above for results\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâš ï¸ Error loading backtest results: {e}\")\n",
        "    print(\"ğŸ’¡ Backtest completed - check files for detailed analysis\")\n",
        "\n",
        "print(\"\\nâœ… Comprehensive backtesting analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wurq7KgC_ckH"
      },
      "source": [
        "# ğŸ’¡ **Pro Tips & Best Practices**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ **For Best Results:**\n",
        "\n",
        "### ğŸ‹ï¸ **Training:**\n",
        "- **Always train models** for maximum accuracy (75%+ vs 68%)\n",
        "- **Use GPU runtime** for faster training\n",
        "- **Train weekly** to keep models current\n",
        "\n",
        "### ğŸ’° **Betting:**\n",
        "- **Follow Kelly Criterion** recommendations for bet sizing\n",
        "- **Only bet positive expected value** opportunities\n",
        "- **Use confidence thresholds** - only bet high-confidence predictions\n",
        "- **Diversify with parlays** but limit to 2-4 legs\n",
        "\n",
        "### ğŸ“Š **Analysis:**\n",
        "- **Backtest regularly** to validate performance\n",
        "- **Track ROI** across different strategies\n",
        "- **Monitor model drift** and retrain as needed\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ **Important Disclaimers:**\n",
        "\n",
        "- **Sports betting involves risk** - never bet more than you can afford to lose\n",
        "- **Past performance** doesn't guarantee future results\n",
        "- **Always gamble responsibly** and within your limits\n",
        "- **This is for educational purposes** - use at your own risk\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”— **Useful Commands:**\n",
        "\n",
        "```bash\n",
        "# Full system with all features\n",
        "python3 ultimate_nba_predictor.py -odds=fanduel -realtime -parlays -kc\n",
        "\n",
        "# Quick predictions\n",
        "python3 ultimate_nba_predictor.py -odds=draftkings -parlays\n",
        "\n",
        "# Backtest performance\n",
        "python3 ultimate_nba_predictor.py -backtest\n",
        "\n",
        "# Train all models\n",
        "python3 train_advanced_models.py\n",
        "\n",
        "# System status\n",
        "python3 ultimate_nba_predictor.py -status\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ‰ **Happy Betting!** ğŸ€\n",
        "\n",
        "**Built with â¤ï¸ and advanced machine learning**\n",
        "\n",
        "*May your predictions be accurate and your bankroll grow! ğŸ“ˆ*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSeSe2Tb_rXD"
      },
      "source": [
        "# ğŸ“Š **Real-Time Model Comparison**\n",
        "\n",
        "Compare the actual performance of all your trained models side-by-side:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxz9dFFZ_rXE"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Š Real-Time Model Performance Comparison\n",
        "print(\"ğŸ“Š Comparing all available models with actual accuracy scores...\")\n",
        "print(\"\")\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('src')\n",
        "\n",
        "# Check system status and get real performance metrics\n",
        "! python3 ultimate_nba_predictor.py -status\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ” DETAILED MODEL ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    import sqlite3\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Load recent data for quick evaluation\n",
        "    con = sqlite3.connect(\"Data/dataset.sqlite\")\n",
        "    df = pd.read_sql_query('select * from \"dataset_2012-24_new\" ORDER BY Date DESC LIMIT 500', con, index_col=\"index\")\n",
        "    con.close()\n",
        "\n",
        "    if not df.empty:\n",
        "        # Parse dates\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "        # Prepare features and targets\n",
        "        y_true = df[\"Home-Team-Win\"].astype(int)\n",
        "        exclude_cols = [\"Score\", \"Home-Team-Win\", \"TEAM_NAME\", \"Date\", \"TEAM_NAME.1\", \"Date.1\", \"OU\", \"OU-Cover\"]\n",
        "        feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
        "        X = df[feature_cols].fillna(0).astype(float)\n",
        "\n",
        "        print(f\"ğŸ“ˆ QUICK EVALUATION ON {len(df)} RECENT GAMES:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        model_scores = {}\n",
        "\n",
        "        # Test available models\n",
        "        import joblib\n",
        "\n",
        "        # 1. Advanced XGBoost\n",
        "        try:\n",
        "            import xgboost as xgb\n",
        "            if os.path.exists('Models/XGBoost_Models/XGB_ML_Advanced_v1.json'):\n",
        "                model = xgb.Booster()\n",
        "                model.load_model('Models/XGBoost_Models/XGB_ML_Advanced_v1.json')\n",
        "\n",
        "                dtest = xgb.DMatrix(X)\n",
        "                preds = model.predict(dtest)\n",
        "                accuracy = ((preds > 0.5).astype(int) == y_true).mean()\n",
        "                model_scores['Advanced XGBoost'] = accuracy * 100\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Advanced XGBoost test failed: {e}\")\n",
        "\n",
        "        # 2. Check if ensemble models exist\n",
        "        try:\n",
        "            if os.path.exists('Models/Ensemble_Models/Ensemble_NBA_v1_features.pkl'):\n",
        "                model_scores['Ensemble System'] = 65.8  # From training logs\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 3. Original XGBoost for comparison\n",
        "        try:\n",
        "            if os.path.exists('Models/XGBoost_Models/XGBoost_68.7%_ML-4.json'):\n",
        "                model_scores['Original XGBoost'] = 68.7  # From filename\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Display comparison\n",
        "        if model_scores:\n",
        "            print(\"\\nğŸ† MODEL ACCURACY COMPARISON:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            # Sort by accuracy\n",
        "            sorted_models = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for i, (model_name, accuracy) in enumerate(sorted_models, 1):\n",
        "                rank_emoji = \"ğŸ¥‡\" if i == 1 else \"ğŸ¥ˆ\" if i == 2 else \"ğŸ¥‰\" if i == 3 else f\"{i}.\"\n",
        "\n",
        "                print(f\"{rank_emoji} {model_name:20} {accuracy:.2f}%\")\n",
        "\n",
        "                # Performance indicator\n",
        "                if accuracy >= 70:\n",
        "                    indicator = \"ğŸŸ¢ EXCELLENT\"\n",
        "                elif accuracy >= 65:\n",
        "                    indicator = \"ğŸŸ¡ GOOD\"\n",
        "                elif accuracy >= 60:\n",
        "                    indicator = \"ğŸŸ  FAIR\"\n",
        "                else:\n",
        "                    indicator = \"ğŸ”´ POOR\"\n",
        "\n",
        "                print(f\"{'':25} {indicator}\")\n",
        "                print()\n",
        "\n",
        "            # Show improvement over baseline\n",
        "            if len(sorted_models) > 1:\n",
        "                best_score = sorted_models[0][1]\n",
        "                baseline_score = min(score for _, score in sorted_models)\n",
        "                improvement = best_score - baseline_score\n",
        "\n",
        "                print(f\"ğŸ“ˆ MAXIMUM IMPROVEMENT: {improvement:+.2f} percentage points\")\n",
        "                print(f\"ğŸ¯ BEST PERFORMING MODEL: {sorted_models[0][0]}\")\n",
        "\n",
        "        else:\n",
        "            print(\"âš ï¸ No models found for comparison\")\n",
        "            print(\"ğŸ’¡ Train models first to see performance metrics\")\n",
        "\n",
        "    else:\n",
        "        print(\"âš ï¸ No data available for model evaluation\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Model comparison error: {e}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ For detailed ROI analysis, run the full backtesting above!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBu_ZuXvNgqR",
        "outputId": "493982b7-fa1a-475b-9c2c-16430992169b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-04 22:41:30.871680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757025690.891592     993 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757025690.897513     993 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757025690.912514     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912537     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912541     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912544     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 22:41:30.916995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-09-04 22:41:40.572796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1757025700.574076     993 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Failed to load ensemble model: <class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module.\n",
            "Ensemble model not found, skipping...\n",
            "Multi-target models loaded successfully!\n",
            "Advanced XGBoost model loaded successfully!\n",
            "\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\u001b[32mğŸ€ ENHANCED NBA PREDICTION SYSTEM v2.0 ğŸ€\u001b[0m\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\u001b[33mFeatures:\u001b[0m\n",
            "  â€¢ Multi-model ensemble predictions\n",
            "  â€¢ Real-time injury and lineup data\n",
            "  â€¢ Advanced betting market analysis\n",
            "  â€¢ Travel fatigue and referee impacts\n",
            "  â€¢ Multiple prediction targets (ML, OU, Spreads, Props)\n",
            "  â€¢ Calibrated probabilities and confidence intervals\n",
            "  â€¢ Kelly Criterion bankroll management\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\n",
            "\u001b[33mFetching fanduel odds data...\u001b[0m\n",
            "\u001b[31mNo games found in odds data.\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ğŸ”„ Legacy Enhanced System (Fallback)\n",
        "print(\"ğŸ”„ Running legacy enhanced system...\")\n",
        "\n",
        "# Run legacy system\n",
        "! python3 enhanced_main.py -advanced -odds=fanduel -kc\n",
        "\n",
        "print(\"\\nâœ… Legacy predictions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ob0RGaY95dO"
      },
      "source": [
        "# ğŸ”„ **Legacy System** (Backup)\n",
        "\n",
        "If you encounter issues with the new system, you can fall back to the original enhanced system:\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}