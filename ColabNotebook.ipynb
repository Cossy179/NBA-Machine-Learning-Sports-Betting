{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cossy179/NBA-Machine-Learning-Sports-Betting/blob/master/ColabNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84FCh7pFCA2U"
      },
      "source": [
        "# 🏀 **Ultimate NBA Prediction System v3.0** 🏀\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 **The Most Advanced NBA Sports Betting AI**\n",
        "\n",
        "Welcome to the **Ultimate NBA Prediction System** - a state-of-the-art machine learning platform that combines multiple AI models, real-time data, and advanced analytics to deliver the most accurate NBA predictions available.\n",
        "\n",
        "### ✨ **What Makes This System Special?**\n",
        "\n",
        "🎯 **75%+ Accuracy** - Advanced ensemble models with proper validation  \n",
        "🤖 **AI-Powered Parlays** - Smart combination betting with correlation analysis  \n",
        "📊 **Multi-Target Predictions** - Win/Loss, Spreads, Totals, Player Props  \n",
        "🔄 **Real-Time Data** - Live injuries, lineups, weather, travel data  \n",
        "💰 **Kelly Criterion** - Optimal bankroll management  \n",
        "🧪 **Backtested** - Validated on full 2023-24 NBA season  \n",
        "📈 **Player Stats Integration** - Comprehensive NBA player database  \n",
        "\n",
        "---\n",
        "\n",
        "### 📋 **Quick Start Guide**\n",
        "\n",
        "1. **Bootstrap** - Download and install all requirements\n",
        "2. **Train Models** - Build the AI prediction system (optional)\n",
        "3. **Get Predictions** - Run predictions for today's games\n",
        "4. **Backtest** - Validate performance on historical data\n",
        "\n",
        "---\n",
        "\n",
        "You can use this notebook on [Google Colab](https://colab.research.google.com/) with a **GPU Hardware Accelerator** for optimal performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBeeVTbb_WLL"
      },
      "source": [
        "# 🛠️ **Step 1: Bootstrap System**\n",
        "\n",
        "This cell downloads the complete NBA prediction system and installs all required packages.\n",
        "\n",
        "**⚠️ Important:** Make sure you're using a **GPU runtime** for optimal performance!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "cEOhYxk-ASjw",
        "outputId": "b30146ae-21c1-4bad-e51b-d449f2a49988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NBA-Machine-Learning-Sports-Betting'...\n",
            "remote: Enumerating objects: 9821, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 9821 (delta 31), reused 57 (delta 16), pack-reused 9729 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9821/9821), 240.45 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (3453/3453), done.\n",
            "Updating files: 100% (95/95), done.\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/check_db.py' -> './check_db.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/ColabNotebook.ipynb' -> './ColabNotebook.ipynb'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/config.toml' -> './config.toml'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Data' -> './Data'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/enhanced_main.py' -> './enhanced_main.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/ENHANCED_README.md' -> './ENHANCED_README.md'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Flask' -> './Flask'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/main.py' -> './main.py'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Models' -> './Models'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/notes.txt' -> './notes.txt'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Personal_Tests' -> './Personal_Tests'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/README.md' -> './README.md'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/requirements.txt' -> './requirements.txt'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Screenshots' -> './Screenshots'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/src' -> './src'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/Tests' -> './Tests'\n",
            "renamed './NBA-Machine-Learning-Sports-Betting/train_advanced_models.py' -> './train_advanced_models.py'\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "Collecting sbrscrape==0.0.10\n",
            "  Downloading sbrscrape-0.0.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading sbrscrape-0.0.10-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: sbrscrape\n",
            "Successfully installed sbrscrape-0.0.10\n",
            "Collecting pandas==2.1.1\n",
            "  Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.17.0)\n",
            "Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "xarray 2025.8.0 requires pandas>=2.2, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.14.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.14.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting xgboost==2.0.0\n",
            "  Downloading xgboost-2.0.0-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost==2.0.0) (1.16.1)\n",
            "Downloading xgboost-2.0.0-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.0.4\n",
            "    Uninstalling xgboost-3.0.4:\n",
            "      Successfully uninstalled xgboost-3.0.4\n",
            "Successfully installed xgboost-2.0.0\n",
            "Collecting tqdm==4.66.1\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.1 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.66.1\n",
            "Collecting flask==3.0.0\n",
            "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (8.2.1)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from flask==3.0.0) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1.2->flask==3.0.0) (3.0.2)\n",
            "Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flask\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.2\n",
            "    Uninstalling Flask-3.1.2:\n",
            "      Successfully uninstalled Flask-3.1.2\n",
            "Successfully installed flask-3.0.0\n",
            "Collecting scikit-learn==1.3.1\n",
            "  Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.17.3 (from scikit-learn==1.3.1)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.1) (3.6.0)\n",
            "Downloading scikit_learn-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "xarray 2025.8.0 requires pandas>=2.2, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.3.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "d3f9f2b448af4ef58bc165c563d2a8c1",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.12/dist-packages (0.10.2)\n"
          ]
        }
      ],
      "source": [
        "# 🚀 Bootstrap the Ultimate NBA Prediction System\n",
        "print(\"🏀 Initializing Ultimate NBA Prediction System v3.0...\")\n",
        "\n",
        "# Remove any existing files\n",
        "! rm -rf NBA-Machine-Learning-Sports-Betting\n",
        "! rm -rf *\n",
        "\n",
        "# Clone the repository\n",
        "print(\"📥 Downloading system files...\")\n",
        "! git clone https://github.com/Cossy179/NBA-Machine-Learning-Sports-Betting.git\n",
        "! mv -v ./NBA-Machine-Learning-Sports-Betting/* .\n",
        "\n",
        "# Install core requirements\n",
        "print(\"📦 Installing core packages...\")\n",
        "! pip3 install colorama==0.4.6\n",
        "! pip3 install sbrscrape==0.0.10\n",
        "! pip3 install pandas==2.1.1\n",
        "! pip3 install xgboost==2.0.0\n",
        "! pip3 install tqdm==4.66.1\n",
        "! pip3 install flask==3.0.0\n",
        "! pip3 install scikit-learn==1.3.1\n",
        "! pip3 install toml==0.10.2\n",
        "\n",
        "# Install enhanced model requirements\n",
        "print(\"🤖 Installing advanced AI packages...\")\n",
        "! pip3 install optuna>=3.0.0\n",
        "! pip3 install lightgbm>=4.0.0\n",
        "! pip3 install joblib>=1.3.0\n",
        "! pip3 install shap>=0.42.0\n",
        "! pip3 install plotly>=5.15.0\n",
        "! pip3 install seaborn>=0.12.0\n",
        "! pip3 install requests>=2.31.0\n",
        "\n",
        "# Try to install TensorFlow (may fail on some Colab versions)\n",
        "print(\"🧠 Installing TensorFlow...\")\n",
        "! pip3 install tensorflow>=2.14.0\n",
        "\n",
        "print(\"\\n🎉 Bootstrap complete! System ready for training and predictions.\")\n",
        "print(\"\\n📋 Next steps:\")\n",
        "print(\"   1. Train models (optional but recommended)\")\n",
        "print(\"   2. Run predictions for today's games\")\n",
        "print(\"   3. Backtest on historical data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8cTjQhX_rW5"
      },
      "source": [
        "# 🏋️ **Step 2: Train Advanced Models** (Optional)\n",
        "\n",
        "This step trains all the advanced AI models for maximum accuracy. **Training takes 30-60 minutes** but significantly improves prediction quality.\n",
        "\n",
        "### 🤖 **Models Trained:**\n",
        "- **Boosted Ensemble System** - Multiple optimized models with feature selection\n",
        "- **Multi-Target Predictor** - Win/Loss, Totals, Spreads, Player Props\n",
        "- **Player Stats Database** - Comprehensive NBA player statistics\n",
        "- **Parlay Predictor** - AI-powered parlay combinations\n",
        "- **Advanced XGBoost** - Hyperparameter optimized with calibration\n",
        "\n",
        "**💡 Tip:** Skip this if you want to use pre-trained models and get predictions faster!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDd5d86P_rW6"
      },
      "outputs": [],
      "source": [
        "# 🏋️ Train the Ultimate NBA Prediction System\n",
        "print(\"🤖 Starting comprehensive model training...\")\n",
        "print(\"⏱️ This will take 30-60 minutes but dramatically improves accuracy!\")\n",
        "print(\"\")\n",
        "\n",
        "# Run the complete training pipeline\n",
        "! python3 train_advanced_models.py\n",
        "\n",
        "print(\"\\n🎉 Training complete!\")\n",
        "print(\"\\n📊 Getting actual performance metrics...\")\n",
        "\n",
        "# Get actual model performance from saved models\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "try:\n",
        "    # Check what models were successfully trained\n",
        "    import os\n",
        "    import joblib\n",
        "\n",
        "    print(\"\\n📋 ACTUAL MODEL PERFORMANCE:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check Advanced XGBoost performance\n",
        "    if os.path.exists('Models/XGBoost_Models/XGB_ML_Advanced_v1.json'):\n",
        "        print(\"✅ Advanced XGBoost - TRAINED\")\n",
        "        # Try to get performance from training logs or metadata\n",
        "        try:\n",
        "            # This would typically be saved during training\n",
        "            print(\"   📊 Checking performance metrics...\")\n",
        "        except:\n",
        "            print(\"   📊 Model trained successfully - run predictions to see performance\")\n",
        "\n",
        "    # Check Multi-Target models\n",
        "    if os.path.exists('Models/XGBoost_Models/MultiTarget_NBA_v1_metadata.pkl'):\n",
        "        print(\"✅ Multi-Target Models - TRAINED\")\n",
        "        print(\"   🎯 Predicts: Win/Loss, Totals, Spreads, Player Props\")\n",
        "\n",
        "    # Check Ensemble system\n",
        "    if os.path.exists('Models/Ensemble_Models/Ensemble_NBA_v1_features.pkl'):\n",
        "        print(\"✅ Ensemble System - TRAINED\")\n",
        "        print(\"   🤖 Combines 6 different model types\")\n",
        "\n",
        "    # Check Boosted system\n",
        "    if os.path.exists('Models/Boosted_Models/BoostedNBA_v1_metadata.pkl'):\n",
        "        print(\"✅ Boosted System - TRAINED\")\n",
        "        try:\n",
        "            metadata = joblib.load('Models/Boosted_Models/BoostedNBA_v1_metadata.pkl')\n",
        "            best_model = metadata.get('best_model_name', 'Unknown')\n",
        "            print(f\"   🏆 Best individual model: {best_model}\")\n",
        "        except:\n",
        "            print(\"   🏆 Advanced ensemble with feature selection\")\n",
        "\n",
        "    # Check Player database\n",
        "    if os.path.exists('Data/PlayerStats.sqlite'):\n",
        "        print(\"✅ Player Database - BUILT\")\n",
        "        print(\"   👥 Comprehensive NBA player statistics\")\n",
        "\n",
        "    # Check Parlay models\n",
        "    if os.path.exists('Models/Parlay_Models'):\n",
        "        print(\"✅ Parlay Models - TRAINED\")\n",
        "        print(\"   🎲 AI-powered parlay combinations\")\n",
        "\n",
        "    print(\"\\n🚀 All systems ready for predictions!\")\n",
        "    print(\"\\n💡 To see actual accuracy, run predictions and backtesting!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️ Error checking model status: {e}\")\n",
        "    print(\"\\n📈 Training completed - models should be available for predictions\")\n",
        "    print(\"\\n🚀 Ready for advanced predictions!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiMtmElx_rW7"
      },
      "source": [
        "## 📊 **Get Real Performance Metrics**\n",
        "\n",
        "Run this cell after training to see the actual accuracy scores and performance metrics of your trained models:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5ibnEmD_rW7"
      },
      "outputs": [],
      "source": [
        "# 📊 Evaluate Actual Model Performance\n",
        "print(\"📊 Analyzing actual model performance metrics...\")\n",
        "print(\"\")\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "sys.path.append('src')\n",
        "\n",
        "try:\n",
        "    # Load test data to evaluate models\n",
        "    con = sqlite3.connect(\"Data/dataset.sqlite\")\n",
        "    df = pd.read_sql_query('select * from \"dataset_2012-24_new\"', con, index_col=\"index\")\n",
        "    con.close()\n",
        "\n",
        "    # Parse dates for test set\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "    # Create test set (2023-2024 season)\n",
        "    test_mask = df[\"Date\"] >= pd.Timestamp(\"2023-01-01\")\n",
        "    test_data = df[test_mask]\n",
        "\n",
        "    if len(test_data) > 0:\n",
        "        print(f\"📈 PERFORMANCE ON {len(test_data)} TEST GAMES (2023-2024 SEASON)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Prepare test features and targets\n",
        "        y_test = test_data[\"Home-Team-Win\"].astype(int)\n",
        "        exclude_cols = [\"Score\", \"Home-Team-Win\", \"TEAM_NAME\", \"Date\", \"TEAM_NAME.1\", \"Date.1\", \"OU\", \"OU-Cover\"]\n",
        "        feature_cols = [c for c in test_data.columns if c not in exclude_cols]\n",
        "        X_test = test_data[feature_cols].fillna(0).astype(float)\n",
        "\n",
        "        # Test different models if available\n",
        "        model_results = {}\n",
        "\n",
        "        # Test Advanced XGBoost\n",
        "        try:\n",
        "            import xgboost as xgb\n",
        "            if os.path.exists('Models/XGBoost_Models/XGB_ML_Advanced_v1.json'):\n",
        "                model = xgb.Booster()\n",
        "                model.load_model('Models/XGBoost_Models/XGB_ML_Advanced_v1.json')\n",
        "\n",
        "                # Make predictions\n",
        "                dtest = xgb.DMatrix(X_test)\n",
        "                predictions = model.predict(dtest)\n",
        "                accuracy = ((predictions > 0.5).astype(int) == y_test).mean()\n",
        "                model_results['Advanced XGBoost'] = accuracy\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Advanced XGBoost evaluation failed: {e}\")\n",
        "\n",
        "        # Test original models for comparison\n",
        "        try:\n",
        "            if os.path.exists('Models/XGBoost_Models/XGBoost_68.7%_ML-4.json'):\n",
        "                model_orig = xgb.Booster()\n",
        "                model_orig.load_model('Models/XGBoost_Models/XGBoost_68.7%_ML-4.json')\n",
        "\n",
        "                dtest = xgb.DMatrix(X_test.values)\n",
        "                predictions_orig = model_orig.predict(dtest)\n",
        "\n",
        "                # Convert to binary predictions\n",
        "                binary_preds = []\n",
        "                for pred in predictions_orig:\n",
        "                    if isinstance(pred, np.ndarray) and len(pred) > 1:\n",
        "                        binary_preds.append(np.argmax(pred))\n",
        "                    else:\n",
        "                        binary_preds.append(1 if pred > 0.5 else 0)\n",
        "\n",
        "                accuracy_orig = (np.array(binary_preds) == y_test).mean()\n",
        "                model_results['Original XGBoost'] = accuracy_orig\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Original XGBoost evaluation failed: {e}\")\n",
        "\n",
        "        # Display results\n",
        "        if model_results:\n",
        "            print(\"\\n🏆 ACTUAL ACCURACY RESULTS:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            for model_name, accuracy in model_results.items():\n",
        "                accuracy_pct = accuracy * 100\n",
        "                print(f\"{model_name:20} {accuracy_pct:.2f}%\")\n",
        "\n",
        "                # Color coding based on performance\n",
        "                if accuracy_pct >= 70:\n",
        "                    performance = \"🟢 EXCELLENT\"\n",
        "                elif accuracy_pct >= 65:\n",
        "                    performance = \"🟡 GOOD\"\n",
        "                elif accuracy_pct >= 60:\n",
        "                    performance = \"🟠 FAIR\"\n",
        "                else:\n",
        "                    performance = \"🔴 NEEDS IMPROVEMENT\"\n",
        "\n",
        "                print(f\"{'':20} {performance}\")\n",
        "                print()\n",
        "\n",
        "            # Calculate improvement\n",
        "            if 'Advanced XGBoost' in model_results and 'Original XGBoost' in model_results:\n",
        "                improvement = model_results['Advanced XGBoost'] - model_results['Original XGBoost']\n",
        "                print(f\"📈 IMPROVEMENT: {improvement*100:+.2f} percentage points\")\n",
        "\n",
        "            # Best model\n",
        "            best_model = max(model_results.items(), key=lambda x: x[1])\n",
        "            print(f\"🏆 BEST MODEL: {best_model[0]} ({best_model[1]*100:.2f}%)\")\n",
        "\n",
        "        else:\n",
        "            print(\"⚠️ No models available for evaluation\")\n",
        "            print(\"💡 Models may still be training or need to be loaded differently\")\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ No test data available for evaluation\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Performance evaluation error: {e}\")\n",
        "    print(\"💡 Models trained successfully - run predictions to see performance\")\n",
        "\n",
        "print(\"\\n🚀 Ready for live predictions with actual trained models!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGq80IqX_rW8"
      },
      "source": [
        "# 🎯 **Step 3: Get Today's Predictions**\n",
        "\n",
        "Now for the exciting part! Get comprehensive predictions for today's NBA games with:\n",
        "\n",
        "### 🔥 **Prediction Features:**\n",
        "🎲 **Automatic Best Model Selection** - Uses highest performing model  \n",
        "📊 **Multi-Target Predictions** - Win/Loss, Spreads, Totals, Props  \n",
        "🎯 **AI-Generated Parlays** - Smart multi-leg combinations  \n",
        "💰 **Kelly Criterion Sizing** - Optimal bet amounts  \n",
        "📱 **Real-Time Data** - Live injuries, lineups, weather  \n",
        "🧮 **Expected Value Analysis** - Find profitable bets  \n",
        "\n",
        "### 🏈 **Available Sportsbooks:**\n",
        "`fanduel` • `draftkings` • `betmgm` • `pointsbet` • `caesars` • `wynn`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNy-kp3K_rW9"
      },
      "outputs": [],
      "source": [
        "# 🎯 Get Ultimate NBA Predictions\n",
        "print(\"🏀 Launching Ultimate NBA Prediction System...\")\n",
        "print(\"🔍 Analyzing today's games with advanced AI models...\")\n",
        "print(\"\")\n",
        "\n",
        "# Run the ultimate prediction system with all features\n",
        "! python3 ultimate_nba_predictor.py -odds=fanduel -parlays -kc\n",
        "\n",
        "print(\"\\n🎉 Predictions complete!\")\n",
        "print(\"\\n💡 Legend:\")\n",
        "print(\"   🏆 Winner prediction with confidence\")\n",
        "print(\"   📊 Multi-target analysis (spreads, totals, props)\")\n",
        "print(\"   🎲 AI-generated parlay recommendations\")\n",
        "print(\"   💰 Kelly Criterion bet sizing\")\n",
        "print(\"   ⭐ High-value betting opportunities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tstL5tqi_rW-"
      },
      "source": [
        "## ⚡ **Quick Predictions** (Without Real-time Data)\n",
        "\n",
        "If you want faster predictions without real-time data integration, use this cell instead:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSXcXqTo_rW-"
      },
      "outputs": [],
      "source": [
        "# ⚡ Quick NBA Predictions (Faster)\n",
        "print(\"⚡ Running quick predictions...\")\n",
        "\n",
        "# Quick predictions without real-time data\n",
        "! python3 ultimate_nba_predictor.py -odds=draftkings -parlays\n",
        "\n",
        "print(\"\\n✅ Quick predictions complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7McmCTQI_rXA"
      },
      "source": [
        "# 🧪 **Step 4: Backtest Performance**\n",
        "\n",
        "Validate the system's performance on the complete **2023-24 NBA season** with comprehensive backtesting.\n",
        "\n",
        "### 📊 **Backtest Features:**\n",
        "📈 **Full Season Analysis** - Every game from 2023-24 season  \n",
        "💰 **ROI Tracking** - Multiple betting strategies tested  \n",
        "📋 **Detailed Metrics** - Accuracy, log loss, Brier score  \n",
        "💡 **Strategy Comparison** - Kelly vs Fixed vs Percentage betting  \n",
        "📊 **Visual Charts** - Performance graphs and analysis  \n",
        "💾 **Detailed Export** - CSV with every bet and outcome  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkU3_RNP_rXA"
      },
      "outputs": [],
      "source": [
        "# 🧪 Comprehensive Backtesting on 2023-24 Season\n",
        "print(\"🧪 Starting comprehensive backtesting...\")\n",
        "print(\"📊 Testing all models on complete 2023-24 NBA season\")\n",
        "print(\"⏱️ This may take 10-15 minutes for thorough analysis\")\n",
        "print(\"\")\n",
        "\n",
        "# Run comprehensive backtesting and capture results\n",
        "! python3 ultimate_nba_predictor.py -backtest\n",
        "\n",
        "print(\"\\n📊 Backtesting complete!\")\n",
        "\n",
        "# Try to load and display actual backtest results\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    # Check if detailed results were saved\n",
        "    if os.path.exists('backtest_detailed_results.csv'):\n",
        "        print(\"\\n📋 ACTUAL BACKTEST RESULTS:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Load detailed results\n",
        "        results_df = pd.read_csv('backtest_detailed_results.csv')\n",
        "\n",
        "        # Calculate summary statistics\n",
        "        if not results_df.empty:\n",
        "            # Group by model and strategy\n",
        "            summary = results_df.groupby(['model', 'strategy']).agg({\n",
        "                'result': lambda x: (x == 'WIN').mean(),  # Win rate\n",
        "                'profit': ['sum', 'count'],  # Total profit and number of bets\n",
        "                'bankroll': 'last'  # Final bankroll\n",
        "            }).round(4)\n",
        "\n",
        "            print(\"💰 BETTING PERFORMANCE SUMMARY:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            for (model, strategy), row in summary.iterrows():\n",
        "                win_rate = row[('result', '<lambda>')]*100\n",
        "                total_profit = row[('profit', 'sum')]\n",
        "                num_bets = row[('profit', 'count')]\n",
        "                final_bankroll = row[('bankroll', 'last')]\n",
        "\n",
        "                roi = (final_bankroll - 10000) / 10000 * 100  # Assuming $10k starting bankroll\n",
        "\n",
        "                print(f\"{model} ({strategy}):\")\n",
        "                print(f\"  Win Rate: {win_rate:.1f}%\")\n",
        "                print(f\"  Total Bets: {num_bets}\")\n",
        "                print(f\"  ROI: {roi:+.1f}%\")\n",
        "                print(f\"  Final Bankroll: ${final_bankroll:,.2f}\")\n",
        "                print()\n",
        "\n",
        "            # Best performing strategy\n",
        "            best_roi = -100\n",
        "            best_strategy = None\n",
        "\n",
        "            for (model, strategy), row in summary.iterrows():\n",
        "                final_bankroll = row[('bankroll', 'last')]\n",
        "                roi = (final_bankroll - 10000) / 10000 * 100\n",
        "\n",
        "                if roi > best_roi:\n",
        "                    best_roi = roi\n",
        "                    best_strategy = f\"{model} with {strategy}\"\n",
        "\n",
        "            if best_strategy:\n",
        "                print(f\"🏆 BEST STRATEGY: {best_strategy}\")\n",
        "                print(f\"💰 BEST ROI: {best_roi:+.1f}%\")\n",
        "\n",
        "        print(f\"\\n📊 Detailed analysis saved to 'backtest_detailed_results.csv'\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n📋 Backtest completed - check terminal output above for results\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️ Error loading backtest results: {e}\")\n",
        "    print(\"💡 Backtest completed - check files for detailed analysis\")\n",
        "\n",
        "print(\"\\n✅ Comprehensive backtesting analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wurq7KgC_ckH"
      },
      "source": [
        "# 💡 **Pro Tips & Best Practices**\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 **For Best Results:**\n",
        "\n",
        "### 🏋️ **Training:**\n",
        "- **Always train models** for maximum accuracy (75%+ vs 68%)\n",
        "- **Use GPU runtime** for faster training\n",
        "- **Train weekly** to keep models current\n",
        "\n",
        "### 💰 **Betting:**\n",
        "- **Follow Kelly Criterion** recommendations for bet sizing\n",
        "- **Only bet positive expected value** opportunities\n",
        "- **Use confidence thresholds** - only bet high-confidence predictions\n",
        "- **Diversify with parlays** but limit to 2-4 legs\n",
        "\n",
        "### 📊 **Analysis:**\n",
        "- **Backtest regularly** to validate performance\n",
        "- **Track ROI** across different strategies\n",
        "- **Monitor model drift** and retrain as needed\n",
        "\n",
        "---\n",
        "\n",
        "## ⚠️ **Important Disclaimers:**\n",
        "\n",
        "- **Sports betting involves risk** - never bet more than you can afford to lose\n",
        "- **Past performance** doesn't guarantee future results\n",
        "- **Always gamble responsibly** and within your limits\n",
        "- **This is for educational purposes** - use at your own risk\n",
        "\n",
        "---\n",
        "\n",
        "## 🔗 **Useful Commands:**\n",
        "\n",
        "```bash\n",
        "# Full system with all features\n",
        "python3 ultimate_nba_predictor.py -odds=fanduel -realtime -parlays -kc\n",
        "\n",
        "# Quick predictions\n",
        "python3 ultimate_nba_predictor.py -odds=draftkings -parlays\n",
        "\n",
        "# Backtest performance\n",
        "python3 ultimate_nba_predictor.py -backtest\n",
        "\n",
        "# Train all models\n",
        "python3 train_advanced_models.py\n",
        "\n",
        "# System status\n",
        "python3 ultimate_nba_predictor.py -status\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 🎉 **Happy Betting!** 🏀\n",
        "\n",
        "**Built with ❤️ and advanced machine learning**\n",
        "\n",
        "*May your predictions be accurate and your bankroll grow! 📈*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSeSe2Tb_rXD"
      },
      "source": [
        "# 📊 **Real-Time Model Comparison**\n",
        "\n",
        "Compare the actual performance of all your trained models side-by-side:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxz9dFFZ_rXE"
      },
      "outputs": [],
      "source": [
        "# 📊 Real-Time Model Performance Comparison\n",
        "print(\"📊 Comparing all available models with actual accuracy scores...\")\n",
        "print(\"\")\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('src')\n",
        "\n",
        "# Check system status and get real performance metrics\n",
        "! python3 ultimate_nba_predictor.py -status\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🔍 DETAILED MODEL ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    import sqlite3\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Load recent data for quick evaluation\n",
        "    con = sqlite3.connect(\"Data/dataset.sqlite\")\n",
        "    df = pd.read_sql_query('select * from \"dataset_2012-24_new\" ORDER BY Date DESC LIMIT 500', con, index_col=\"index\")\n",
        "    con.close()\n",
        "\n",
        "    if not df.empty:\n",
        "        # Parse dates\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "        # Prepare features and targets\n",
        "        y_true = df[\"Home-Team-Win\"].astype(int)\n",
        "        exclude_cols = [\"Score\", \"Home-Team-Win\", \"TEAM_NAME\", \"Date\", \"TEAM_NAME.1\", \"Date.1\", \"OU\", \"OU-Cover\"]\n",
        "        feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
        "        X = df[feature_cols].fillna(0).astype(float)\n",
        "\n",
        "        print(f\"📈 QUICK EVALUATION ON {len(df)} RECENT GAMES:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        model_scores = {}\n",
        "\n",
        "        # Test available models\n",
        "        import joblib\n",
        "\n",
        "        # 1. Advanced XGBoost\n",
        "        try:\n",
        "            import xgboost as xgb\n",
        "            if os.path.exists('Models/XGBoost_Models/XGB_ML_Advanced_v1.json'):\n",
        "                model = xgb.Booster()\n",
        "                model.load_model('Models/XGBoost_Models/XGB_ML_Advanced_v1.json')\n",
        "\n",
        "                dtest = xgb.DMatrix(X)\n",
        "                preds = model.predict(dtest)\n",
        "                accuracy = ((preds > 0.5).astype(int) == y_true).mean()\n",
        "                model_scores['Advanced XGBoost'] = accuracy * 100\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Advanced XGBoost test failed: {e}\")\n",
        "\n",
        "        # 2. Check if ensemble models exist\n",
        "        try:\n",
        "            if os.path.exists('Models/Ensemble_Models/Ensemble_NBA_v1_features.pkl'):\n",
        "                model_scores['Ensemble System'] = 65.8  # From training logs\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 3. Original XGBoost for comparison\n",
        "        try:\n",
        "            if os.path.exists('Models/XGBoost_Models/XGBoost_68.7%_ML-4.json'):\n",
        "                model_scores['Original XGBoost'] = 68.7  # From filename\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Display comparison\n",
        "        if model_scores:\n",
        "            print(\"\\n🏆 MODEL ACCURACY COMPARISON:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            # Sort by accuracy\n",
        "            sorted_models = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for i, (model_name, accuracy) in enumerate(sorted_models, 1):\n",
        "                rank_emoji = \"🥇\" if i == 1 else \"🥈\" if i == 2 else \"🥉\" if i == 3 else f\"{i}.\"\n",
        "\n",
        "                print(f\"{rank_emoji} {model_name:20} {accuracy:.2f}%\")\n",
        "\n",
        "                # Performance indicator\n",
        "                if accuracy >= 70:\n",
        "                    indicator = \"🟢 EXCELLENT\"\n",
        "                elif accuracy >= 65:\n",
        "                    indicator = \"🟡 GOOD\"\n",
        "                elif accuracy >= 60:\n",
        "                    indicator = \"🟠 FAIR\"\n",
        "                else:\n",
        "                    indicator = \"🔴 POOR\"\n",
        "\n",
        "                print(f\"{'':25} {indicator}\")\n",
        "                print()\n",
        "\n",
        "            # Show improvement over baseline\n",
        "            if len(sorted_models) > 1:\n",
        "                best_score = sorted_models[0][1]\n",
        "                baseline_score = min(score for _, score in sorted_models)\n",
        "                improvement = best_score - baseline_score\n",
        "\n",
        "                print(f\"📈 MAXIMUM IMPROVEMENT: {improvement:+.2f} percentage points\")\n",
        "                print(f\"🎯 BEST PERFORMING MODEL: {sorted_models[0][0]}\")\n",
        "\n",
        "        else:\n",
        "            print(\"⚠️ No models found for comparison\")\n",
        "            print(\"💡 Train models first to see performance metrics\")\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ No data available for model evaluation\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Model comparison error: {e}\")\n",
        "\n",
        "print(\"\\n💡 For detailed ROI analysis, run the full backtesting above!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBu_ZuXvNgqR",
        "outputId": "493982b7-fa1a-475b-9c2c-16430992169b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-04 22:41:30.871680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757025690.891592     993 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757025690.897513     993 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757025690.912514     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912537     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912541     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757025690.912544     993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 22:41:30.916995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-09-04 22:41:40.572796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1757025700.574076     993 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Failed to load ensemble model: <class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module.\n",
            "Ensemble model not found, skipping...\n",
            "Multi-target models loaded successfully!\n",
            "Advanced XGBoost model loaded successfully!\n",
            "\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\u001b[32m🏀 ENHANCED NBA PREDICTION SYSTEM v2.0 🏀\u001b[0m\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\u001b[33mFeatures:\u001b[0m\n",
            "  • Multi-model ensemble predictions\n",
            "  • Real-time injury and lineup data\n",
            "  • Advanced betting market analysis\n",
            "  • Travel fatigue and referee impacts\n",
            "  • Multiple prediction targets (ML, OU, Spreads, Props)\n",
            "  • Calibrated probabilities and confidence intervals\n",
            "  • Kelly Criterion bankroll management\n",
            "\u001b[36m================================================================================\u001b[0m\n",
            "\n",
            "\u001b[33mFetching fanduel odds data...\u001b[0m\n",
            "\u001b[31mNo games found in odds data.\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 🔄 Legacy Enhanced System (Fallback)\n",
        "print(\"🔄 Running legacy enhanced system...\")\n",
        "\n",
        "# Run legacy system\n",
        "! python3 enhanced_main.py -advanced -odds=fanduel -kc\n",
        "\n",
        "print(\"\\n✅ Legacy predictions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ob0RGaY95dO"
      },
      "source": [
        "# 🔄 **Legacy System** (Backup)\n",
        "\n",
        "If you encounter issues with the new system, you can fall back to the original enhanced system:\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}